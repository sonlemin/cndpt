#!/usr/bin/env python3
"""
analyze_other_jobs.py

Script phÃ¢n tÃ­ch cÃ¡c job titles trong nhÃ³m "other" Ä‘á»ƒ tÃ¬m patterns
vÃ  Ä‘á» xuáº¥t cÃ¡ch cáº£i thiá»‡n classification.

USAGE:
    cd ~/workspace/github.com/sonlemin/cndpt/code/code
    python src/analyze_other_jobs.py
"""

import pandas as pd
from collections import Counter
import re

def extract_keywords(title):
    """Extract potential keywords from job title"""
    # Lowercase and split
    words = title.lower().split()
    
    # Common keywords to look for
    keywords = []
    
    # Check for specific patterns
    patterns = {
        'senior': r'\bsenior\b|\bsr\b',
        'junior': r'\bjunior\b|\bjr\b',
        'lead': r'\blead\b|\bleader\b',
        'manager': r'\bmanager\b|\bquáº£n lÃ½\b',
        'developer': r'\bdeveloper\b|\bdev\b|\bláº­p trÃ¬nh\b',
        'engineer': r'\bengineer\b|\bká»¹ sÆ°\b',
        'specialist': r'\bspecialist\b|\bchuyÃªn viÃªn\b',
        'consultant': r'\bconsultant\b|\btÆ° váº¥n\b',
        'architect': r'\barchitect\b|\bkiáº¿n trÃºc\b',
        'admin': r'\badmin\b|\bquáº£n trá»‹\b',
        'support': r'\bsupport\b|\bhá»— trá»£\b',
        'coordinator': r'\bcoordinator\b|\bÄ‘iá»u phá»‘i\b',
        'analyst': r'\banalyst\b',
        'tester': r'\btester\b|\btest\b',
        'designer': r'\bdesigner\b|\bthiáº¿t káº¿\b',
    }
    
    title_lower = title.lower()
    for keyword, pattern in patterns.items():
        if re.search(pattern, title_lower):
            keywords.append(keyword)
    
    return keywords

def analyze_other_jobs(csv_path):
    """Analyze job titles in 'other' group"""
    print("="*80)
    print("ğŸ” PHÃ‚N TÃCH NHÃ“M 'OTHER'")
    print("="*80)
    
    # Load data
    try:
        df = pd.read_csv(csv_path)
    except FileNotFoundError:
        print(f"âŒ File not found: {csv_path}")
        print("   HÃ£y cháº¡y 04_extract_features_improved.py trÆ°á»›c")
        return
    
    # Filter "other" group
    other_df = df[df["job_group"] == "other"].copy()
    total_other = len(other_df)
    total_jobs = len(df)
    
    print(f"\nğŸ“Š Tá»•ng quan:")
    print(f"  Total jobs: {total_jobs}")
    print(f"  'other' jobs: {total_other} ({total_other/total_jobs*100:.1f}%)")
    print(f"  Cáº§n phÃ¢n loáº¡i: {total_other} jobs")
    
    # Show sample titles
    print(f"\nğŸ“„ Máº«u 30 job titles trong 'other' (ngáº«u nhiÃªn):")
    print("-" * 80)
    sample = other_df["tieu_de"].sample(min(30, len(other_df))).tolist()
    for i, title in enumerate(sample, 1):
        print(f"{i:2d}. {title}")
    
    # Analyze keywords
    print(f"\nğŸ”¤ PhÃ¢n tÃ­ch tá»« khÃ³a phá»• biáº¿n:")
    print("-" * 80)
    
    all_keywords = []
    for title in other_df["tieu_de_clean"]:
        keywords = extract_keywords(title)
        all_keywords.extend(keywords)
    
    keyword_counts = Counter(all_keywords)
    for keyword, count in keyword_counts.most_common(20):
        pct = count / total_other * 100
        print(f"  {keyword:20s}: {count:4d} jobs ({pct:5.1f}%)")
    
    # Analyze common words
    print(f"\nğŸ’¬ Tá»« xuáº¥t hiá»‡n nhiá»u trong job titles:")
    print("-" * 80)
    
    all_words = []
    for title in other_df["tieu_de_clean"]:
        words = title.split()
        all_words.extend([w for w in words if len(w) > 3])  # Skip short words
    
    word_counts = Counter(all_words)
    for word, count in word_counts.most_common(30):
        pct = count / total_other * 100
        print(f"  {word:20s}: {count:4d} ({pct:5.1f}%)")
    
    # Suggest patterns
    print(f"\nğŸ’¡ Äá»€ XUáº¤T PATTERNS Má»šI:")
    print("-" * 80)
    print("\nDá»±a trÃªn phÃ¢n tÃ­ch, cÃ³ thá»ƒ thÃªm cÃ¡c patterns sau vÃ o config:")
    print("")
    
    suggestions = []
    
    # Check for common patterns
    if 'developer' in keyword_counts and keyword_counts['developer'] > 10:
        suggestions.append(("software_engineer", r"\bdeveloper\b|\bdev\b|\bláº­p trÃ¬nh viÃªn\b"))
    
    if 'engineer' in keyword_counts and keyword_counts['engineer'] > 10:
        suggestions.append(("software_engineer", r"\bengineer\b|\bká»¹ sÆ°\b"))
    
    if 'senior' in keyword_counts and keyword_counts['senior'] > 10:
        print("âš ï¸  Nhiá»u 'senior' titles - CÃ³ thá»ƒ cáº§n xá»­ lÃ½ level riÃªng")
    
    if 'support' in keyword_counts and keyword_counts['support'] > 5:
        suggestions.append(("support", r"\bsupport\b|\bhá»— trá»£\b|\bhelp desk\b"))
    
    if 'admin' in keyword_counts and keyword_counts['admin'] > 5:
        suggestions.append(("admin", r"\badmin\b|\bquáº£n trá»‹\b|\bsystem admin\b"))
    
    # Print suggestions
    for group, pattern in suggestions:
        print(f"  ('{group}', r'{pattern}'),")
    
    # Export full list for manual review
    output_file = "data/processed/other_jobs_analysis.csv"
    other_df[["tieu_de", "tieu_de_clean"]].to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"\nğŸ’¾ ÄÃ£ xuáº¥t full list ra: {output_file}")
    print("   Review file nÃ y Ä‘á»ƒ tÃ¬m thÃªm patterns!")
    
    print("\n" + "="*80)
    print("âœ… HOÃ€N Táº¤T PHÃ‚N TÃCH")
    print("="*80)
    print("\nNext steps:")
    print("  1. Review suggestions phÃ­a trÃªn")
    print("  2. Check file: data/processed/other_jobs_analysis.csv")
    print("  3. Update config vá»›i patterns má»›i")
    print("  4. Re-run: python src/04_extract_features_improved.py")

if __name__ == "__main__":
    analyze_other_jobs("data/processed/topcv_it_features.csv")